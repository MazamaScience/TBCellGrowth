################################################################################
# HINT:  How to set up a CIDR cluster session with more memory.
#
# email from Erik Swanson:
#
# We have Linux control groups enabled, so jobs will be killed if they use more 
# than 1 GB of memory on the cluster node.  Our cluster nodes are configured with 
# 250000MB memory in SLURM, so I suggest you use a variation of the command below 
# and adjust the number cores to match the amount of memory you think the job will 
# need.  This command will request an interactive session and use all the memory 
# and cores on one node.  If you change “-n=16” to “-n=2”, then the job will get 2 
# CPUs and ~32 GB of memory.  You can also use these flags with the sbatch command.
#
# $ srun --mem-per-cpu=15625 -n16 -N1 --pty --preserve-env $SHELL
#
# man page:  srun [OPTIONS...]  executable [args...]
#
################################################################################


################################################################################
# Examples to be run on CIDR shell06
################################################################################

# Not much growth but we can go all the way through (phase only)
srun --mem-per-cpu=15626 -n2 -N1 --pty --preserve-env ./flow_exec.R \
--inputDir="/nearline/sherman-ngs/KM_Temp_Imaging/Microfluidics/BSL3/CellAsic, RvC, RPL22, & pEXCF-0023, 6-29-15" \
--outputDir="/nethome/jcallahan/Projects/Sherman/Results/Jun29" \
--chambers="xy01" \
--channels="c1" --channelNames="phase" \
--nFrames="8" \
--verbose &


################################################################################
################################################################################
################################################################################


################################################################################
# Examples to be run on the Mazama Science desktop machine
################################################################################

# Not much growth but we can go all the way through (phase only)
./flow_exec.R --inputDir="/Volumes/MazamaData1/Data/TBData/CellAsic, RvC, RPL22, & pEXCF-0023, 6-29-15" --outputDir="~/TBResults/June29" --chambers="xy01,xy06" --channels="c1" --channelNames="phase" --nFrames=8 --verbose &

# Rapid growth 
./flow_exec.R --inputDir="/Volumes/MazamaData1/Data/TBData/CellAsic, RvC, limiting PI, 9-1-15" --dataDir="Experimental images" --outputDir="~/TBResults/Sep01" --chambers="xy01,xy02,xy03,xy04,xy05,xy06" --channels="c1,c3" --channelNames="phase,red" --nFrames=20 --startFrame=8 --backgroundIndex=2 --verbose &

# 2015-09-23
./flow_exec.R \
--inputDir="/Volumes/MazamaData1/Data/TBData/CellAsic, RvC Phage Delivery of GFP, 9-23-15" \
--dataDir="Experimental Images" \
--outputDir="~/TBResults/Sep23" \
--chambers="xy04" \
--channels="c1,c3" \
--channelNames="phase,green" \
--backgroundIndex=2 \
--startFrame=1 \
--timestep=2 \
--nFrames=12 \
--distanceScale=0.22 \
--verbose &


# Rapid growth
./flow_exec.R \
--inputDir="/Volumes/MazamaData1/Data/TBData/CellAsic, RvC, limiting PI, 9-1-15" \
--dataDir="Experimental images" \
--outputDir="~/TBResults/Sep01" \
--chambers="xy05" \
--channels="c1,c3" \
--channelNames="phase,green" \
--backgroundIndex=2 \
--startFrame=8 \
--minTimespan=3 \
--nFrames=4 \
--distanceScale=0.22 \
--noHyperlinks \
--verbose &


# Looking for problem creating full-frame images
./solid_exec.R \
--inputDir="/Volumes/sherman-ngs/KM_Temp_Imaging/Alginate INH treatment & Macs, 11-6-15" \
--dataDir="Experimental Images" \
--outputDir="/Users/jonathan/Projects/CIDR/Sherman/JC_Results/DELETEME" \
--chambers="xy01" \
--channels="c1" \
--channelNames="phase1" \
--startFrame=1 \
--nFrames=3 \
--minTimespan=2 \
--timestep=3 \
--distanceScale=0.21 \
--verbose &
  
################################################################################
# Post processing
#
# Options:
# 	--inputDir=INPUTDIR
# 		Absolute path of the input directory [default ""]
# 
# 	--phaseCsv=PHASECSV
# 		Name of the 'phase' CSV file to process [default ""]
# 
# 	--outputDir=OUTPUTDIR
# 		Absolute path of the output directory [default "CURRENT_DIRECTORY"]
# 
# 	--minExpFitHour=MINEXPFITHOUR
# 		Hour of first datapoint to include in doubling time exponential fit [default "0"]
# 
# 	--maxExpFitHour=MAXEXPFITHOUR
# 		Hour of last datapoint to include in doubling time exponential fit [default "1e+09"]
# 
# 	--minDoublingTime=MINDOUBLINGTIME
# 		Colonies with doubling times smaller than this many hours are removed [default "0"]
# 
# 	--maxDoublingTime=MAXDOUBLINGTIME
# 		Colonies with doubling times larger than this many hours are removed [default "1e+09"]
# 
# 	--removeOutliers=REMOVEOUTLIERS
# 		Flag indicating whether to remove colonies with doubling time outliers [default "TRUE"]
# 
# 	--maxStartHour=MAXSTARTHOUR
# 		Colonies not identified by this hour are removed  [default "60"]
# 
# 	-h, --help
# 		Show this help message and exit
# 
################################################################################

./analysis_exec.r \
--inputDir="/Volumes/sherman-ngs/JC_Results/TEST_flow.0.2.2/xy01/" \
--phaseCsv="phase_xy01.csv" \
--minExpFitHour=24 \
--maxExpFitHour=60 \
--minDoublingTime=0.1 \
--maxDoublingTime=60 \
--removeOutliers=TRUE \
--maxStartHour=60


./analysis_exec.r \
--inputDir="/Volumes/sherman-ngs/JC_Results/TEST_solid.0.2.2/xy01/" \
--phaseCsv="phase_xy01.csv" \
--minExpFitHour=24 \
--maxExpFitHour=60 \
--minDoublingTime=0.1 \
--maxDoublingTime=60 \
--removeOutliers=TRUE \
--maxStartHour=60


